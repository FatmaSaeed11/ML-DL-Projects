# -*- coding: utf-8 -*-
"""Assignment 5_ pattern_numpy_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SBjr-JmXmz8M2ul1YAHvLQ1JwQ1pZeDY

import libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score

"""import dataset from kaggel"""

!pip install kaggle

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d shivanandmn/multilabel-classification-dataset

from zipfile import ZipFile
dataset='/content/multilabel-classification-dataset.zip'

with ZipFile(dataset,'r') as zip:
  zip.extractall()
  print('data extracted')

"""data preparation"""

data_train=pd.read_csv('/content/train.csv')

features = data_train['ABSTRACT'] + ' ' + data_train['TITLE']

targets = data_train[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]
print(targets)

"""tokanization"""

vectorizer = TfidfVectorizer(max_features=5000)
x = vectorizer.fit_transform(features)

"""convert targets to numpy array"""

targets=np.array(targets)

"""train test split"""

x_train, x_test, y_train, y_test = train_test_split(x, targets, test_size=0.2, random_state=42)

print('x_train',x_train)

print('x_test',x_test)

"""build our model"""

def sigmoid ( x ) :
 return 1 / (1 + np . exp ( - x ) )

def sigmoid_derivative ( x ) :
 return x * (1 - x )

"""compile our model"""

class LinearNN:
    def __init__(self, n_inputs, n_outputs):
        self.weights = np.random.rand(n_inputs, n_outputs)
        self.bias = np.random.rand(n_outputs)

    def train(self, X, T, epochs, lr):
        for epoch in range(epochs):

            y_pred = self.predict(X)

            # Compute gradient
            d_weights = np.dot(X.T, (y_pred - T) * sigmoid_derivative(y_pred))
            d_bias = np.sum((y_pred - T) * sigmoid_derivative(y_pred), axis=0)


            self.weights -= lr * d_weights
            self.bias -= lr * d_bias

            if epoch % 100 == 0:
                loss = np.mean(-T * np.log(y_pred) - (1 - T) * np.log(1 - y_pred))
                print(f'Loss at epoch {epoch}: {loss}')

    def predict(self, X):
        return sigmoid(np.dot(X, self.weights) + self.bias)


model = LinearNN(x_train.shape[1], y_train.shape[1])
model.train(x_train, y_train, epochs=5000, lr=0.001)

"""make prediction to get total accuracy"""

y_pred= np.round(model.predict(x_test))
accuracy = np.mean((y_pred == y_test).all(axis=1))
print(f'Accuracy: {accuracy}')