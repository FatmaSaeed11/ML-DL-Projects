{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "import libraries"
      ],
      "metadata": {
        "id": "WgGCYp8NE4Sj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PCKbkRwoD2T-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import dataset from kaggel"
      ],
      "metadata": {
        "id": "MXBEt0UPE8Ij"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d shivanandmn/multilabel-classification-dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "dataset='/content/multilabel-classification-dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('data extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o7KPnDaD82y",
        "outputId": "8207f940-113d-4ab0-fc1c-ecbe51cb6881"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n",
            "Downloading multilabel-classification-dataset.zip to /content\n",
            "  0% 0.00/11.4M [00:00<?, ?B/s]\n",
            "100% 11.4M/11.4M [00:00<00:00, 164MB/s]\n",
            "data extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data preparation"
      ],
      "metadata": {
        "id": "8QxauAMKM43x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_train=pd.read_csv('/content/train.csv')\n"
      ],
      "metadata": {
        "id": "kBf50iMJEEpi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = data_train['ABSTRACT'] + ' ' + data_train['TITLE']\n"
      ],
      "metadata": {
        "id": "oC8vc-ZCESfE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targets = data_train[['Computer Science', 'Physics', 'Mathematics', 'Statistics', 'Quantitative Biology', 'Quantitative Finance']]\n",
        "print(targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HjJh_RkEWLT",
        "outputId": "3648eba7-e3c3-4ed5-85ed-37e6732d3ce8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Computer Science  Physics  Mathematics  Statistics  \\\n",
            "0                     1        0            0           0   \n",
            "1                     1        0            0           0   \n",
            "2                     0        0            1           0   \n",
            "3                     0        0            1           0   \n",
            "4                     1        0            0           1   \n",
            "...                 ...      ...          ...         ...   \n",
            "20967                 1        1            0           0   \n",
            "20968                 0        1            0           0   \n",
            "20969                 1        0            0           0   \n",
            "20970                 0        0            1           1   \n",
            "20971                 0        0            1           1   \n",
            "\n",
            "       Quantitative Biology  Quantitative Finance  \n",
            "0                         0                     0  \n",
            "1                         0                     0  \n",
            "2                         0                     0  \n",
            "3                         0                     0  \n",
            "4                         0                     0  \n",
            "...                     ...                   ...  \n",
            "20967                     0                     0  \n",
            "20968                     0                     0  \n",
            "20969                     0                     0  \n",
            "20970                     0                     0  \n",
            "20971                     0                     0  \n",
            "\n",
            "[20972 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokanization"
      ],
      "metadata": {
        "id": "QET2MDJ7EyEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "x = vectorizer.fit_transform(features)"
      ],
      "metadata": {
        "id": "Ah0Pt4TeExje"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "convert targets to numpy array"
      ],
      "metadata": {
        "id": "X3unH50BFE2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets=np.array(targets)"
      ],
      "metadata": {
        "id": "Vw0ZnQO4FKQG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train test split"
      ],
      "metadata": {
        "id": "qWcf_IfnFSH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, targets, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2gOoFjI6FU6a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_train',x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ofAHGTEtFv",
        "outputId": "8e59a696-570c-4e8c-f53b-f1bc5a3efdb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('x_test',x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai65-O7uEwHO",
        "outputId": "a7ed9ec4-c213-470e-c419-4106ca503bbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_test [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "build our model"
      ],
      "metadata": {
        "id": "l02ZcgM1NLnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid ( x ) :\n",
        " return 1 / (1 + np . exp ( - x ) )\n",
        "\n",
        "def sigmoid_derivative ( x ) :\n",
        " return x * (1 - x )"
      ],
      "metadata": {
        "id": "pfF2vGAJq6Uf"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "compile our model"
      ],
      "metadata": {
        "id": "FTvpQ96VNXhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNN:\n",
        "    def __init__(self, n_inputs, n_outputs):\n",
        "        self.weights = np.random.rand(n_inputs, n_outputs)\n",
        "        self.bias = np.random.rand(n_outputs)\n",
        "\n",
        "    def train(self, X, T, epochs, lr):\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            y_pred = self.predict(X)\n",
        "\n",
        "            # Compute gradient\n",
        "            d_weights = np.dot(X.T, (y_pred - T) * sigmoid_derivative(y_pred))\n",
        "            d_bias = np.sum((y_pred - T) * sigmoid_derivative(y_pred), axis=0)\n",
        "\n",
        "\n",
        "            self.weights -= lr * d_weights\n",
        "            self.bias -= lr * d_bias\n",
        "\n",
        "            if epoch % 100 == 0:\n",
        "                loss = np.mean(-T * np.log(y_pred) - (1 - T) * np.log(1 - y_pred))\n",
        "                print(f'Loss at epoch {epoch}: {loss}')\n",
        "\n",
        "    def predict(self, X):\n",
        "        return sigmoid(np.dot(X, self.weights) + self.bias)\n",
        "\n",
        "\n",
        "model = LinearNN(x_train.shape[1], y_train.shape[1])\n",
        "model.train(x_train, y_train, epochs=5000, lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXSaZ7UhGuLp",
        "outputId": "806fdc00-6986-4860-97ce-8b46099c307c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss at epoch 0: 3.3245466418525114\n",
            "Loss at epoch 100: 0.3695312723303342\n",
            "Loss at epoch 200: 0.31662374849444375\n",
            "Loss at epoch 300: 0.2876938511518868\n",
            "Loss at epoch 400: 0.2697731738802322\n",
            "Loss at epoch 500: 0.2573970557720262\n",
            "Loss at epoch 600: 0.2481846631217689\n",
            "Loss at epoch 700: 0.24096034474603134\n",
            "Loss at epoch 800: 0.2350766315269479\n",
            "Loss at epoch 900: 0.23014577983178353\n",
            "Loss at epoch 1000: 0.2259201986892351\n",
            "Loss at epoch 1100: 0.2222336664525279\n",
            "Loss at epoch 1200: 0.21897002943736374\n",
            "Loss at epoch 1300: 0.21604542121226758\n",
            "Loss at epoch 1400: 0.2133976134084213\n",
            "Loss at epoch 1500: 0.2109793514613357\n",
            "Loss at epoch 1600: 0.20875402727035142\n",
            "Loss at epoch 1700: 0.20669277960987004\n",
            "Loss at epoch 1800: 0.204772498076304\n",
            "Loss at epoch 1900: 0.20297441668085017\n",
            "Loss at epoch 2000: 0.20128310294639806\n",
            "Loss at epoch 2100: 0.1996857190184766\n",
            "Loss at epoch 2200: 0.19817147426348075\n",
            "Loss at epoch 2300: 0.19673121559626683\n",
            "Loss at epoch 2400: 0.19535711875733988\n",
            "Loss at epoch 2500: 0.19404245465591038\n",
            "Loss at epoch 2600: 0.19278141194992113\n",
            "Loss at epoch 2700: 0.1915689616553176\n",
            "Loss at epoch 2800: 0.19040075266479722\n",
            "Loss at epoch 2900: 0.18927302918538158\n",
            "Loss at epoch 3000: 0.18818256265820257\n",
            "Loss at epoch 3100: 0.18712659201853055\n",
            "Loss at epoch 3200: 0.18610276750456162\n",
            "Loss at epoch 3300: 0.1851090948893995\n",
            "Loss at epoch 3400: 0.18414387902878418\n",
            "Loss at epoch 3500: 0.18320566767415278\n",
            "Loss at epoch 3600: 0.18229319803235003\n",
            "Loss at epoch 3700: 0.18140534907573755\n",
            "Loss at epoch 3800: 0.18054110203902907\n",
            "Loss at epoch 3900: 0.17969951025550665\n",
            "Loss at epoch 4000: 0.1788796780700641\n",
            "Loss at epoch 4100: 0.17808074749785546\n",
            "Loss at epoch 4200: 0.17730189077565933\n",
            "Loss at epoch 4300: 0.17654230692532477\n",
            "Loss at epoch 4400: 0.17580122073445492\n",
            "Loss at epoch 4500: 0.1750778829705095\n",
            "Loss at epoch 4600: 0.1743715710472324\n",
            "Loss at epoch 4700: 0.17368158968870845\n",
            "Loss at epoch 4800: 0.17300727136791155\n",
            "Loss at epoch 4900: 0.17234797644272287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make prediction to get total accuracy"
      ],
      "metadata": {
        "id": "Vy7g6Z9LHf51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred= np.round(model.predict(x_test))\n",
        "accuracy = np.mean((y_pred == y_test).all(axis=1))\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rc4jT_lGHdAx",
        "outputId": "8057e749-ab9c-4ee8-9bce-fcc62a8a7a84"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6436233611442194\n"
          ]
        }
      ]
    }
  ]
}